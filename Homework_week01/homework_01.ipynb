{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad0b4fb",
   "metadata": {},
   "source": [
    "Hey, I'm Jobert Gutierrez and hereafter you'll find the logic and code used to answer the first assignment in the program Machine Learning Operations Zoomcamp offered by Data Talks Club.\n",
    "\n",
    "# Module 1 Homework: General Overview and foundations\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module.\n",
    "\n",
    "## Question 1. Downloading the data\n",
    "We'll use the same [NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page), but instead of \"Green Taxi Trip Records\", we'll use \"Yellow Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2023.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "- 16\n",
    "- 17\n",
    "- 18\n",
    "- 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef021ac7",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n",
    "I downloaded the data using this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For January 2023:\n",
    "python -m wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\n",
    "\n",
    "# For February 2023:\n",
    "python -m wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e03d42",
   "metadata": {},
   "source": [
    "\n",
    "Then, I read the January file as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4599fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the libraries used:\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54c54cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(r'C:/Users/jober/OneDrive/Desktop/mlops-hw2025/Homework_week01/yellow_tripdata_2023-01.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d84394",
   "metadata": {},
   "source": [
    "The number of columns is identified using the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7761595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3066766 entries, 0 to 3066765\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      "dtypes: datetime64[us](2), float64(12), int64(4), object(1)\n",
      "memory usage: 444.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726fdd1",
   "metadata": {},
   "source": [
    "## Question 2. Computing duration\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "- 32.59\n",
    "- 42.59\n",
    "- 52.59\n",
    "- 62.59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e843ccfe",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n",
    "The duration of the trips are calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "298c7b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.594351241920904"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The amount of time for each ride is:\n",
    "df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "\n",
    "# Expressed in mutes is:\n",
    "df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "# The stard deviation of the ride's duration is: \n",
    "df.duration.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b6cf1d",
   "metadata": {},
   "source": [
    "## Question 3. Dropping outliers\n",
    "Next, we need to check the distribution of the `duration` variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "- 90%\n",
    "- 92%\n",
    "- 95%\n",
    "- 98%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa33b2",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n",
    "The distribution of duration variables are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb4f34e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of rows with outliers is: 3066766\n",
      "the number of rows without outliers is: 3009173\n"
     ]
    }
   ],
   "source": [
    "# The number of registries before removing outliers is:\n",
    "r_before = len(df)\n",
    "print(f'the number of rows with outliers is: {r_before}')\n",
    "\n",
    "# Removing outliers:\n",
    "df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "# The number of rows without outliers is:\n",
    "r_after = len(df)\n",
    "print(f'the number of rows without outliers is: {r_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78b4a6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then, the fraction of the records left after removing the outliers is: 0.9812202822125979\n"
     ]
    }
   ],
   "source": [
    "fraction = r_after/r_before\n",
    "print(f'Then, the fraction of the records left after removing the outliers is: {fraction}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0602fb",
   "metadata": {},
   "source": [
    "## Question 4. One-hot encoding\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "- Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "- Fit a dictionary vectorizer\n",
    "- Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "- 2\n",
    "- 155\n",
    "- 345\n",
    "- 515\n",
    "- 715"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce3304",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n",
    "The dimensionality is calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c12d7eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3009173, 515)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The categorical variables selected are:\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "strings = ['VendorID', 'RatecodeID']\n",
    "\n",
    "df[categorical] = df[categorical].astype(str)\n",
    "df[strings] = df[strings].astype(str)\n",
    "\n",
    "# Using the variables indicated, the train dictionary is:\n",
    "train_dicts = df[categorical].to_dict(orient='records')\n",
    "\n",
    "# The feature matrix is calculated as:\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# The shape of this matrix is:\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2e8b28",
   "metadata": {},
   "source": [
    "The number of columns of this matrix is __515 columns__."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
